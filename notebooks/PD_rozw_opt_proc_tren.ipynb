{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PD_rozw_opt_proc_tren.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2APrRHXAtumo",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1MjzUke5SDxffqmpruiUzfdBLR6gKbCBM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpTaN2wARjNl",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "< [5. Modele](PD_modele.ipynb) | [7. Rozwiązanie Bazowe.](PD_rozw_bazowe.ipynb) >\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iULHWjzd8im",
        "colab_type": "text"
      },
      "source": [
        "## [6. Rozwiązania optymalizujące proces trenowania.]()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7ejVvXFUB-0",
        "colab_type": "text"
      },
      "source": [
        "Zmiany poprawiające proces uczenia zaimpementowane w [[1] reid-strong-baseline -github](https://github.com/michuanhaohao/reid-strong-baseline) zostały zaprezentowane na grafice umieszczonej poniżej.\n",
        "<br><br>\n",
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/reidTricks.jpg?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
        "<br><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptIMo97ueGHH",
        "colab_type": "text"
      },
      "source": [
        "### 6.1 Rozgrzewanie kroku uczenia (Warmup Learning Rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWCc565k7ias",
        "colab_type": "text"
      },
      "source": [
        "Learning Rate ma bezpośredni wpływ na to jak szybko model zmienia swoje wagi. W celu wygenerowanai statystyk ułatwiających manipulowaniem parameterem Learning Rate przez optymalizator, statuje się mechanizm nazywany \"Rozgrzewaniem kroku uczenia\". Polega on na poświęceniu kilku pierwszych epok na stworzeniu statystyk przy ustawionym domyślnie kroku uczenia na niskim poziomie. W praktyce zaimplementowano to w spoósb:\n",
        " \n",
        " <img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/learning-rate.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-9VsCY2emKh",
        "colab_type": "text"
      },
      "source": [
        "### 6.2 Losowo wycinanie (Random Erasing Augumentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIi9QLc47jd3",
        "colab_type": "text"
      },
      "source": [
        "Losowe wycinanie fragmentów obrazów jest powszechnie stosowanym sposobem augumetacji danych. Ma on na celu uniezależnienie modelu na zmiany, które nie powinny być ważnymi cechami obiektu na ktorego podstawie generowany jest jego embeding.\n",
        "\n",
        "\n",
        "Przykład realizowany na opisanym powyżej datasecie Martek1501:\n",
        "\n",
        " <img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/random_erasing.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlhJqJ95emHe",
        "colab_type": "text"
      },
      "source": [
        "### 6.3 Wygładzanie adnotacji (Label Smoothing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwNsZsgm7k2o",
        "colab_type": "text"
      },
      "source": [
        "Ponieważ adnotacja danych bierze udział w przeliczaniu funkcji strat jako jeden z jej składników, problemem staje się przetrenowanie modelu w kontekście wykrywania właśnie adnotacji. Metodą na prewencję takiej sytuacji jest użycie \"Wygładzania adnotacji\". Polega to rozłożeniu niewielkiej części prawdopodobieństwa na inne klasy. W przypadku rozpatrywanym w tej pracy na bazie zbioru danych Markets1501 inną klasą jest id innej osoby. \n",
        "\n",
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/label_smoothing.png?raw=true\" alt=\"drawing\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxC5-vffgdft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8fd1ecee-4e78-4d8a-9e9e-22b526952b1e"
      },
      "source": [
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "\n",
        "g_truth = {\"Alice\":0,'Bob': 0,'Frank':1,'Mari': 0,'Eve': 0}\n",
        "\n",
        "def pretty_display(var_list):\n",
        "  from prettytable import PrettyTable\n",
        "  t = PrettyTable(['Id_name', 'Ground_truth'])\n",
        "  for i in var_list:\n",
        "    t.add_row([i,var_list[i]])\n",
        "  return t\n",
        "\n",
        "reference_value= pretty_display(g_truth)\n",
        "\n",
        "def label_smoothing(g_truth, eps):\n",
        "  g_truth_len = len(g_truth)\n",
        "  smoothed_list:dict ={}\n",
        "  for i in g_truth:\n",
        "    if g_truth[i] == 1:\n",
        "      smoothed_list[i] = 1-((g_truth_len-1)*eps/g_truth_len)\n",
        "    else:\n",
        "      smoothed_list[i] = eps/g_truth_len\n",
        "  return smoothed_list\n",
        "\n",
        "print(reference_value)\n",
        "print(\"////// Label Smoothing //////\")\n",
        "reference_value_after_label_smoothing = pretty_display(label_smoothing(g_truth,0.05))\n",
        "print(reference_value_after_label_smoothing) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------------+\n",
            "| Id_name | Ground_truth |\n",
            "+---------+--------------+\n",
            "|  Alice  |      0       |\n",
            "|   Bob   |      0       |\n",
            "|  Frank  |      1       |\n",
            "|   Mari  |      0       |\n",
            "|   Eve   |      0       |\n",
            "+---------+--------------+\n",
            "////// Label Smoothing //////\n",
            "+---------+--------------+\n",
            "| Id_name | Ground_truth |\n",
            "+---------+--------------+\n",
            "|  Alice  |     0.01     |\n",
            "|   Bob   |     0.01     |\n",
            "|  Frank  |     0.96     |\n",
            "|   Mari  |     0.01     |\n",
            "|   Eve   |     0.01     |\n",
            "+---------+--------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRmLz57WemDu",
        "colab_type": "text"
      },
      "source": [
        "### 6.4 Zmiana ostatniego warstwy konwolucyjnej (Last Stride)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLpCXj367lbH",
        "colab_type": "text"
      },
      "source": [
        "Jedną z potrzeb jakie adresują wartwy konwolucyjne to agregacja wymiarów cech rozwiniętych przez poprzednie warstwy. Modyfikacja dotycząca tego punktu polega na ograniczeniu agregacji cech ostatniej warstwy i pozostawienia wiekszej reprezentacji cech głębokich sieci stanowiącej backbone trenowanego modelu. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcrNO1Kvelw2",
        "colab_type": "text"
      },
      "source": [
        "### 6.5 BBNeck"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj20kTve7mn4",
        "colab_type": "text"
      },
      "source": [
        "Dużą część pracy jaką poświęcili twórcy framework-u użytego w tej pracy, stanowiła zmiana opisana jako BBNeck.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/bnn-modify.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
        "\n",
        "\n",
        "Jak zaprezentowano na załączonej ilustracji zaczerpniętej z pracy [[6]](https://arxiv.org/pdf/1903.07071.pdf) w przypadku a) będącym typowym podejściem ID loss i triplet loss działają na tym samej warstwie cech głębokich (embedding-ów). W takiej sytuacji lepiej sprawdza się przeliczenie dystansu cosinusowego czyli porównanie kierunków wyznaczonych przez wektory w przestrzeni embeddingów. Natomiast w przypadku b) wykorzystanie odległości euklidesowej w przestrzeni wektorów embeddingów sprzyja zagęszczaniu wyników wewnątrz klasową oraz zwiększanie odległości między zbiorami należacymi do innych klas. Ponieważ zagęszczanie wyników wewnątrz jednej klasy może zdecydowanie szybciej minimalizować funkcję strat triple loss, niż zwiększania odległości między klasowej wprowadzono kolejną warstwę cech głębokich. Kolejna warstwa jest znormalizowaną warstwą cech głębokich (embeddingów). Idea stojąca za takim krokiem polega na wymuszeniu stałej długości wektorów cech dla różnych klas. Zwiększa to znaczenie zwiększania odległości między różnymi klasami, co prowadzi do ograniczenia problemu minimalizacji międzyklasowej \"kosztem\" maksymalizacji odległości międzyklasowej. Idę bardzo dobrze ilustruje grafika zawarta w pracy [[6]](https://arxiv.org/pdf/1903.07071.pdf)\n",
        "\n",
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/bnn-modify-2.png?raw=true\" alt=\"drawing\" width=\"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73nPWLDRfet6",
        "colab_type": "text"
      },
      "source": [
        "### 6.6 Center Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsKDtik9w1V5",
        "colab_type": "text"
      },
      "source": [
        "To rozwiązanie dodające do fukcji strat bezpośredni człon odpowidzialny za penalizowanie dużych rozbieżności w obrębie jednej klasy. Formuła na przeliczenie takiego członu zaprezentowano poniżej:\n",
        "\n",
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/center-loss.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
        "\n",
        "W rezultacie funkcja strat posiada trzy człony zaprazentowane poniżej:\n",
        "\n",
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/loss-fun.png?raw=true\" alt=\"drawing\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b1XT0wuzC4q",
        "colab_type": "text"
      },
      "source": [
        "### 6.7 Podsumowanie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3QUD9rIzH-M",
        "colab_type": "text"
      },
      "source": [
        "W pracy [[6]](https://arxiv.org/pdf/1903.07071.pdf) zaprezentowano wyniki jakie dają użycie poszczególnych usprawnienień opisanych powyżej. To zestawienie wygląda jak poniżej:\n",
        "\n",
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/trick-summarization.png?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
        "\n",
        "Jest to unikatowa wartość jaką wprowadza praca [[6]](https://arxiv.org/pdf/1903.07071.pdf). Daję ona wiarygone informację jaką jakościową zmianę można spodziewać się z użycia każdego z usprawnień i zaplanowanie wiarygodnego porównania zmian wprowadzanych do modeli. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5nCEpYmZS8P",
        "colab_type": "text"
      },
      "source": [
        "## Nawigacja\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BZLfh4L0ZU9_"
      },
      "source": [
        "<br>\n",
        "\n",
        "< [5. Modele](PD_modele.ipynb) | [7. Rozwiązanie Bazowe.](PD_rozw_bazowe.ipynb) >\n"
      ]
    }
  ]
}