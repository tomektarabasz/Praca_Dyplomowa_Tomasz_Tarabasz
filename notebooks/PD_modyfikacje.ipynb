{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PD_modyfikacje.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bFGtx6YIBTY-",
        "PNJQOIifj8P9",
        "-5tRaErRAyjn",
        "8IvHVlyM1FAq",
        "w7zgKoTfA7vl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2APrRHXAtumo",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1MjzUke5SDxffqmpruiUzfdBLR6gKbCBM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7VcYmp9qcq4T"
      },
      "source": [
        "<br>\n",
        "\n",
        "< [7. Rozwiązanie bazowe](PD_rozw_bazowe.ipynb) | [9. Trening zmodyfikowanych modeli](PD_tren_zmod_modeli.ipynb) >\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBwo6PtHUoz",
        "colab_type": "text"
      },
      "source": [
        "## [8. Modyfikacje]()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLmqIzfF5EOb",
        "colab_type": "text"
      },
      "source": [
        "### 8.1 Inicjalizacja modelu EfficienNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6c2KrRmV2ke",
        "colab_type": "text"
      },
      "source": [
        "Zamnim siec została użyta do reidentyfikacji zainicjalizowano ją oraz przetestowano używając kodu poniżej."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZkd7Gbm5Rtc",
        "colab_type": "text"
      },
      "source": [
        "EfficientNet b0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MrJwaDP5NW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "model_efficient = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "path_to_models = './models/efficientnet-b0.pth'\n",
        "torch.save(model_efficient.state_dict(), path_to_models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqjMpwmj5VDZ",
        "colab_type": "text"
      },
      "source": [
        "EfficientNet b7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_lRC1dA5Xlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "model_efficient = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "path_to_models = './models/efficientnet-b7.pth'\n",
        "torch.save(model_efficient.state_dict(), path_to_models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fy4hUCekrrN",
        "colab_type": "text"
      },
      "source": [
        "### 8.2 Użycie jako sieci bazowej sieci EfficientNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOOseUsNift_",
        "colab_type": "text"
      },
      "source": [
        "Główną modyfikacją jaka została wytestowana w tej pracy było użycie jako sieci bazowej do ekstrakcji cech, sieci EfficientNet. Ten model nie został zaimplementowany i przetestowany w bazowej wersji frameworku. Wiecej na temat powodów wyboru tej sieci przedstawiono w punkcie 5.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G8bpuJygZfx",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/EfficientNetBackBone.png?raw=true\" alt=\"drawing\" width=\"800\"/>\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLrSroUfxdTM",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/TrainEfficientNet.png?raw=true\" alt=\"drawing\" width=\"800\"/>\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bFGtx6YIBTY-"
      },
      "source": [
        "### 8.3 Zmiejszenie rozmiaru embeddingu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qtoyBN_4BTZC"
      },
      "source": [
        "W celu zmniejszenia rozmaru generowanego embeddingu zdecydowano o zmniejszeniu rozmaru ostatniej warstwy sieci z 2048 parametrów do 512. Ma to na celu zmniejszenie rozmiaru ostatecznie zapisywanych danych oraz przyspieszenie procesu przeszukiwania wygenerowanych wektorów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNJQOIifj8P9",
        "colab_type": "text"
      },
      "source": [
        "### 8.4 Zminiejszenie precyzji zapisywanych parametrów do float16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg3mQJJkkNui",
        "colab_type": "text"
      },
      "source": [
        "Zmniejszenie precyzji z jaką zpisywane są parametry w sieci jest istotne dla optymalizacji procesu obliczeń na urządzeniach producenta kart graficznych N-vidia oraz dla samego rozmiaru zapisanego modelu. Poniżej fragmet zmian w kodzie zapewniający transformację precyzji do float16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAYLy53QlDHv",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/ZmniejszeniePrecyzji.png?raw=true\" alt=\"drawing\" width=\"800\"/>\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E9zIuv8zAyjl"
      },
      "source": [
        "### 8.5 Wprowadzenie dodatkowej augumentacji danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5tRaErRAyjn"
      },
      "source": [
        "#### Komórki Pomocnicze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "43DhUEDUAyjo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e512dde-ec9d-47b3-8801-ef1ac8a53ef2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y_y2srj2Ayjx",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import torch\n",
        "class AddingNoise(object):\n",
        "\n",
        "    def __init__(self,probability=0.3, level=0.01):\n",
        "        self.level = level\n",
        "        self.probability = probability\n",
        "\n",
        "    def __call__(self, img_tensor):\n",
        "      if random.uniform(0, 1) >= self.probability:\n",
        "            return img_tensor\n",
        "      delta = torch.rand(img_tensor.shape)\n",
        "      delta.data.clamp_(-self.level, self.level)\n",
        "\n",
        "      img_tensor = img_tensor + delta\n",
        "      return img_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5-8_oiLvAyj4",
        "colab": {}
      },
      "source": [
        "class Market1501Dataset:\n",
        "  def __init__(self, path, img_list, transform):\n",
        "    assert os.path.exists(path)\n",
        "    self.path = path\n",
        "    self.img_list = img_list\n",
        "    self.transform = transform\n",
        "    \n",
        "    self.image_paths =[]    # Ścieżki do kolejnych obrazów\n",
        "    self.class_names = []   # Nazwa klasy każdego obrazu\n",
        "    \n",
        "    for img_name in self.img_list:\n",
        "      img_path = os.path.join(path, img_name)\n",
        "      assert os.path.exists(img_path)\n",
        "      self.image_paths.append(img_path)\n",
        "      pos = img_name.find('_')      # Znajdź pierwsze wystąpienie '_'\n",
        "      class_name = img_name[:pos]     # 4 pierwsze znaki w nazwie pliku są identyfikatorem klasy\n",
        "      self.class_names.append(int(class_name))\n",
        "\n",
        "    self.n_classes = len(set(self.class_names)) # Liczba klas (liczba różnych osób)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)\n",
        "    \n",
        "  def __getitem__(self, ndx):\n",
        "    image_path = self.image_paths[ndx]\n",
        "    im = Image.open(image_path)\n",
        "    _, file_name = os.path.split(image_path)\n",
        "    image = np.asarray(im)\n",
        "    if self.transform is not None:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image, self.class_names[ndx]\n",
        "\n",
        "  def print_info(self):\n",
        "      print('Zbiór danych zawiera {} obrazów z {} klas'.format(len(self), self.n_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VI4cMgxvAykA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ef7cc884-ad00-4342-8529-f85c96a88b43"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, ToPILImage\n",
        "path_tt = './gdrive/My Drive/COCO_Darknet/yolov5s_miki_coco_persons_trained/detections_with_json/cropped'\n",
        "os.path.exists(path_tt)\n",
        "\n",
        "files = os.listdir(path_tt)\n",
        "train_transform_tt = Compose([ToTensor()])\n",
        "tt = Market1501Dataset(path_tt, files, train_transform_tt)\n",
        "print(files.__len__())\n",
        "print(tt)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1738\n",
            "<__main__.Market1501Dataset object at 0x7fac98b4bc18>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dEy0Gp38AykG",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "img = next(iter(tt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vlbYiksTAykK",
        "colab": {}
      },
      "source": [
        "def tensor_to_image_tt(x):\n",
        "  # Konwersja obrazu danego jako znormalizowany tensor do PIL Image\n",
        "  transform = Compose([ToPILImage()])\n",
        "  image = transform(x.cpu())\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IvHVlyM1FAq",
        "colab_type": "text"
      },
      "source": [
        "#### Komórki Pomocnicze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2s9a11t7FDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e512dde-ec9d-47b3-8801-ef1ac8a53ef2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTCbz6O05eMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import torch\n",
        "class AddingNoise(object):\n",
        "\n",
        "    def __init__(self,probability=0.3, level=0.01):\n",
        "        self.level = level\n",
        "        self.probability = probability\n",
        "\n",
        "    def __call__(self, img_tensor):\n",
        "      if random.uniform(0, 1) >= self.probability:\n",
        "            return img_tensor\n",
        "      delta = torch.rand(img_tensor.shape)\n",
        "      delta.data.clamp_(-self.level, self.level)\n",
        "\n",
        "      img_tensor = img_tensor + delta\n",
        "      return img_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6koumOQ_64ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Market1501Dataset:\n",
        "  def __init__(self, path, img_list, transform):\n",
        "    assert os.path.exists(path)\n",
        "    self.path = path\n",
        "    self.img_list = img_list\n",
        "    self.transform = transform\n",
        "    \n",
        "    self.image_paths =[]    # Ścieżki do kolejnych obrazów\n",
        "    self.class_names = []   # Nazwa klasy każdego obrazu\n",
        "    \n",
        "    for img_name in self.img_list:\n",
        "      img_path = os.path.join(path, img_name)\n",
        "      assert os.path.exists(img_path)\n",
        "      self.image_paths.append(img_path)\n",
        "      pos = img_name.find('_')      # Znajdź pierwsze wystąpienie '_'\n",
        "      class_name = img_name[:pos]     # 4 pierwsze znaki w nazwie pliku są identyfikatorem klasy\n",
        "      self.class_names.append(int(class_name))\n",
        "\n",
        "    self.n_classes = len(set(self.class_names)) # Liczba klas (liczba różnych osób)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)\n",
        "    \n",
        "  def __getitem__(self, ndx):\n",
        "    image_path = self.image_paths[ndx]\n",
        "    im = Image.open(image_path)\n",
        "    _, file_name = os.path.split(image_path)\n",
        "    image = np.asarray(im)\n",
        "    if self.transform is not None:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image, self.class_names[ndx]\n",
        "\n",
        "  def print_info(self):\n",
        "      print('Zbiór danych zawiera {} obrazów z {} klas'.format(len(self), self.n_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7xgpCe27Ap-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ef7cc884-ad00-4342-8529-f85c96a88b43"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, ToPILImage\n",
        "path_tt = './gdrive/My Drive/COCO_Darknet/yolov5s_miki_coco_persons_trained/detections_with_json/cropped'\n",
        "os.path.exists(path_tt)\n",
        "\n",
        "files = os.listdir(path_tt)\n",
        "train_transform_tt = Compose([ToTensor()])\n",
        "tt = Market1501Dataset(path_tt, files, train_transform_tt)\n",
        "print(files.__len__())\n",
        "print(tt)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1738\n",
            "<__main__.Market1501Dataset object at 0x7fac98b4bc18>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgvQQo2J-c7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "img = next(iter(tt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXSfm0Jv-eZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tensor_to_image_tt(x):\n",
        "  # Konwersja obrazu danego jako znormalizowany tensor do PIL Image\n",
        "  transform = Compose([ToPILImage()])\n",
        "  image = transform(x.cpu())\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QiXDxqnn4xT",
        "colab_type": "text"
      },
      "source": [
        "Próbą zwiekszenia prezycji wyznaczanych embeddingów \n",
        "<br><br>\n",
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/baselineChanges.png?raw=true\" alt=\"drawing\" width=\"800\"/>\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w7zgKoTfA7vl"
      },
      "source": [
        "### 8.6 Wprowadzenie funkcji Swish jako funkcji aktywacji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UsLTMKJ6A7vo"
      },
      "source": [
        "Funkcja Swish zdefiniowana jako: \n",
        "<br><br>\n",
        "$\\text{Swish}(x) = x \\cdot (1 - {e}^{-x})^{-1}$\n",
        "<br><br>\n",
        "<img src=\"https://github.com/tomektarabasz/Praca_Dyplomowa_Tomasz_Tarabasz/blob/master/img/Swish_plot.jpg?raw=true\" alt=\"drawing\" width=\"400\"/>\n",
        "<br><br>\n",
        "\n",
        "Zgodnie z [[3] Why Swish could perform better than ReLu](https://www.machinecurve.com/index.php/2019/05/30/why-swish-could-perform-better-than-relu/?fbclid=IwAR1muCJQpjU4M4dHcCx2wj3PAtYtL6rpEi5-aU9LSjrkrBONQXTqScR2AtU) taka postać funkcji aktywacji może poprawić wyniki poprzez:\n",
        " - Dla dużych wartości ujemnych, tak jak funkcja ReLu zeruje takie aktywacje.\n",
        " - Dla wartości dodatnich aktywacji funkcja Swish zachowuje się podobnie do ReLu i nie ograniczna tych wartości \"od góry\"\n",
        " - W okolicjach zera funkcja jest różniczkowalna i nie zawiera nielinowości\n",
        " - Małe wartości ujemne nie są zerowane co może pomóc w doszkalaniu modelu w procesie szukania subtelnych cech głębokich."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZpwOBnPBJU7",
        "colab_type": "text"
      },
      "source": [
        "## Nawigacja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y-NvYVJwBGlF"
      },
      "source": [
        "<br>\n",
        "\n",
        "< [7. Rozwiązanie bazowe](PD_rozw_bazowe.ipynb) | [9. Trening zmodyfikowanych modeli](PD_tren_zmod_modeli.ipynb) >\n"
      ]
    }
  ]
}